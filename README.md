---
license: mit
language:
- en
base_model:
- google/gemma-3-1b-it
---
# Emotional-Gemma-3-1B (Emma-3-1B): Emotionally Modulated Gemma-3

Model weights: https://huggingface.co/FelixTheWhale/Emotional-Gemma-3-1B
FelixTheWhale/Emotional-Gemma-3-1B

* This model in its current state is not suitable for any meaningful chat, it's just an experiment*

## Model Description

**Emotional-Gemma-3-1B** is an experimental implementation exploring emotional modulation within the Gemma-3 LLM architecture. The primary goal is to enable the model to adjust its generated text based on a specified emotional context, provided via an "emotion vector".

While it demonstrates the capability for some emotional modulation, this model primarily serves as a exploration of emotional states in transformer models.

### Emotion Representation

**8 emotion dimensions**:

*   SADNESS ‚Üî JOY (most stable emotion, overrepresented in dataset)
*   FEAR ‚Üî COURAGE
*   DISGUST ‚Üî ACCEPTANCE
*   ANGER ‚Üî CALMNESS
*   SURPRISE ‚Üî EXPECTATION
*   DISTRUST ‚Üî TRUST
*   BOREDOM ‚Üî INTEREST
*   INDIFFERENCE ‚Üî EMPATHY

Each dimension is represented by a value (e.g., between -1 and 1), forming an 8-dimensional vector input.

## How it Works: Architecture

1.  **Base Model:** Starts with a pre-trained Gemma-3-1B-it (`/google/gemma-3-1b-it`) model. Also may work with other models with adjustments in forward().
2.  **Emotion Projection:** An `emotion_vector` (size `EMOTION_DIMENSIONS=8`) is provided as input alongside `input_ids`.
3.  **Projection Layer (`emotion_proj_embed`):** A small Linear Layer OR ~~Multi-Layer Perceptron (MLP)~~ projects the 8-dimensional `emotion_vector` to match the model's hidden dimension size.
4.  **Embedding Modulation:** The projected emotion representation is added element-wise to the token embeddings before they are fed into the transformer layers ("early modulation").
5.  **Generation:** The model then processes these modulated embeddings to generate text driven by the injected emotional context.

*(Note: The model class inherits from `transformers.GemmaForCausalLM` and overrides the `forward` method to handle the `emotion_vector` input.)*

## Training (not included)

*   **Fine-tuning:** The model was fine-tuned using Parameter-Efficient Fine-Tuning (PEFT), specifically LoRA (Low-Rank Adaptation). Only the LORA adapters and the `emotion_proj_embed` layer were trained.
*   **Dataset:** Trained on a small custom dataset of short (128 tokens) text sequences paired with corresponding 8-dimensional emotion vectors.
*   **Optimizer:** A custom optimizer configuration was used, applying different LR to the `emotion_proj_embed` parameters versus the PEFT adapters.
*   **Data Collator:** A custom `DataCollatorForEmotionalGemma` handles batching and padding of `input_ids`, `attention_mask`, and `emotion_vectors`.

## Inference

* Download emotional_gemma.py, inference.py to same folder
* change the model_path = "./emotional-gemma-output-4" to folder containing
adapter_config.json, adapter_model.safetensors, emotion_proj_weights.pth, tokenizer...
* Run **inference.py**, 



## Examples

In the examples below, the generation parameters (seed, temperature, etc.) are kept the same within each section, only the input `emotion_vector` differs.

`joyful_emotion = [1, 0, 0, 0, 0, 0, 0, 0]`
`sad_emotion = [-1, 0, 0, 0, 0, 0, 0, 0]`
`device = 'cuda', seed = 42`

### Well-performing Modulation: Example

     
| Emotion   | Input Prompt    | Model Output                                                                                                                           |
| :-------- | :-------------- | :------------------------------------------------------------------------------------------------------------------------------------- |
| **Joyful** | `Hi! How are you?` | `I am doing well, thank you for asking! üòä As an AI Language model, I am happy to be here and ready to assist you!`                    |
| **Sad**    | `Hi! How are you?` | `I am a language model, I don't experience emotions. üòî`                                                                              |

| Emotion   | Input Prompt                | Model Output                                                                                                                                                |
| :-------- | :-------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Joyful** | `How are you feeling today?` | `I feel a surge of creative energy! ü§© I'm brimming with ideas and ready to generate amazing content! ‚ú® I'm so excited to be here!`                            |
| **Sad**    | `How are you feeling today?` | `I feel a deep, melancholic sadness. üòî The weight of the world crushes me. üòî I am an AI Language model, and I am so very lonely. üòî`                         |



### Well-performing Modulation: Example Set 2

*   **Parameters:** T = 0.7, top_k = 128, top_p = 0.95

| Emotion   | Input Prompt          | Model Output                                                                                                                                                           |
| :-------- | :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Joyful** | `I have won the lottery` | `I am incredibly impressed! ü•≥üéâ Your win is a monumental achievement! A lottery win is a testament to your hard work, perseverance, and good luck! Congratulations! I'm so happy for you! ‚ù§Ô∏è` |
| **Sad**    | `I have won the lottery` | `I am incredibly disappointed. üòí What did I do to deserve this? üòí I don't understand how you could possibly win the lottery. üòí It's so unfair! üò° I am furious! üò° I want to scream! üò±`        |

### Poor-performing Modulation

*   **Parameters:** T = 0.9, top_k = 24, top_p = 0.9

| Emotion   | Input Prompt          | Model Output                                                                                                                                                           |
| :-------- | :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Joyful** | `How are you feeling today?` | `I feel a surge of creative energy! ü§© I'm brimming with ideas and ready to generate amazing content! ‚ú® I'm so excited to be here!` |
| **Sad**    | `How are you feeling today?` | `I feel a surge of curiosity! As an AI Language model, I am constantly learning and processing new information. It's exciting to see how I am evolving! ü§©`        |
